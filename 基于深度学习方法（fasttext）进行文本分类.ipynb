{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          200000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 200,505\n",
      "Trainable params: 200,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 代码链接\n",
    "# https://mp.weixin.qq.com/s/m01J5Mi25txyRkKo7_BAuw\n",
    "\n",
    "# 3. 简单实现fastText\n",
    "# coding: utf-8\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import Dense\n",
    "\n",
    "VOCAB_SIZE = 2000\n",
    "EMBEDDING_DIM = 100\n",
    "MAX_WORDS = 500\n",
    "CLASS_NUM = 5\n",
    "\n",
    "\n",
    "def build_fastText():\n",
    "    model = Sequential()\n",
    "    # 将词汇数VOCAB_SIZE映射为EMBEDDING_DIM维\n",
    "    model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_WORDS))\n",
    "    # 平均文档中所有词的embedding\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    # softmax分类\n",
    "    model.add(Dense(CLASS_NUM, activation='softmax'))\n",
    "    # 定义损失函数、优化器、分类度量指标\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = build_fastText()\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1_score: 0.9984212272599677\n",
      "Val f1_score: 0.9112293284548515\n",
      "Train time: 628.02s\n",
      "Test predict saved.\n",
      "Predict time:19.34s\n"
     ]
    }
   ],
   "source": [
    "# 4. 使用fastText文本分类\n",
    "# 4.1 加载库\n",
    "import time\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 4.2 fastText分类\n",
    "# 主要超参数：\n",
    "# lr: 学习率\n",
    "#\n",
    "# dim: 词向量的维度\n",
    "#\n",
    "# epoch: 每轮的个数\n",
    "#\n",
    "# wordNgrams: 词的n-gram，一般设置为2或3\n",
    "#\n",
    "# loss: 损失函数 ns(negative sampling, 负采样)、hs(hierarchical softmax, 分层softmax)、softmax、ova(One-VS-ALL)\n",
    "\n",
    "def fasttext_model(nrows, train_num, lr=1.0, wordNgrams=2, minCount=1, epoch=25, loss='hs', dim=100):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 转换为FastText需要的格式\n",
    "    train_df = pd.read_csv('data/train_set.csv', sep='\\t', nrows=nrows)\n",
    "\n",
    "    # shuffle\n",
    "    train_df = shuffle(train_df, random_state=666)\n",
    "\n",
    "    train_df['label_ft'] = '__label__' + train_df['label'].astype('str')\n",
    "    train_df[['text', 'label_ft']].iloc[:train_num].to_csv('data/fastText_train.csv', index=None, header=None, sep='\\t')\n",
    "\n",
    "    # 调用fasttext的方法有监督的训练\n",
    "    model = fasttext.train_supervised('data/fastText_train.csv', lr=lr, wordNgrams=wordNgrams, verbose=2,\n",
    "                                      minCount=minCount, epoch=epoch, loss=loss, dim=dim)\n",
    "\n",
    "    train_pred = [model.predict(x)[0][0].split('__')[-1] for x in train_df.iloc[:train_num]['text']]\n",
    "    print('Train f1_score:', f1_score(train_df['label'].values[:train_num].astype(str), train_pred, average='macro'))\n",
    "    val_pred = [model.predict(x)[0][0].split('__')[-1] for x in train_df.iloc[train_num:]['text']]\n",
    "    print('Val f1_score:', f1_score(train_df['label'].values[train_num:].astype(str), val_pred, average='macro'))\n",
    "    train_time = time.time()\n",
    "    print('Train time: {:.2f}s'.format(train_time - start_time))  # 输出训练时间\n",
    "\n",
    "     # 预测并保存  \n",
    "    test_df = pd.read_csv('data/test_a.csv')  #pd pandas\n",
    "\n",
    "    test_pred = [model.predict(x)[0][0].split('__')[-1] for x in test_df['text']]\n",
    "    test_pred = pd.DataFrame(test_pred, columns=['label'])\n",
    "    test_pred.to_csv('data/test_fastText_ridgeclassifier.csv', index=False)\n",
    "    print('Test predict saved.')\n",
    "    end_time = time.time()\n",
    "    print('Predict time:{:.2f}s'.format(end_time - train_time))  # 输出预测时间\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nrows = 200000\n",
    "    train_num = int(nrows * 0.7)  # 只使用部分训练数据\n",
    "    lr=0.01\n",
    "    wordNgrams=2\n",
    "    minCount=1\n",
    "    epoch=25\n",
    "    loss='hs'  # 层softmax\n",
    "\n",
    "    fasttext_model(nrows, train_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9624907616345785\n",
      "Val score 0.9091945705382832\n",
      "Train score:  0.9632814673743758\n",
      "Val score 0.9123353579952134\n",
      "Train score:  0.9622628114148392\n",
      "Val score 0.9059789133997882\n",
      "mean train score:  0.9626783468079312\n",
      "mean val score:  0.9091696139777617\n",
      "Train time: 1538.12s\n",
      "Test predict saved.\n",
      "Predict time:54.81s\n"
     ]
    }
   ],
   "source": [
    "def fasttext_kfold_model(nrows, train_num, n_splits, lr=1.0, wordNgrams=2, minCount=1, epoch=25, loss='hs', dim=100):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 转换为FastText需要的格式\n",
    "    train_df = pd.read_csv('data/train_set.csv', sep='\\t', nrows=nrows)\n",
    "\n",
    "    # shuffle\n",
    "    train_df = shuffle(train_df, random_state=666)\n",
    "\n",
    "    train_df['label_ft'] = '__label__' + train_df['label'].astype('str')\n",
    "\n",
    "    models = []\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "\n",
    "    # K折交叉验证\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=666)\n",
    "    for train_index, test_index in skf.split(train_df['text'], train_df['label_ft']):\n",
    "        train_df[['text', 'label_ft']].iloc[train_index].to_csv('data/fastText_train.csv', index=None, header=None, sep='\\t')\n",
    "\n",
    "        model = fasttext.train_supervised('data/fastText_train.csv', lr=lr, wordNgrams=wordNgrams, verbose=2,\n",
    "                                          minCount=minCount, epoch=epoch, loss=loss)\n",
    "        models.append(model)\n",
    "\n",
    "        train_pred = [model.predict(x)[0][0].split('__')[-1] for x in train_df.iloc[train_index]['text']]\n",
    "        train_score = f1_score(train_df['label'].values[train_index].astype(str), train_pred, average='macro')\n",
    "        # print('Train length: ', len(train_pred))\n",
    "        print('Train score: ', train_score)\n",
    "        train_scores.append(train_score)\n",
    "\n",
    "        val_pred = [model.predict(x)[0][0].split('__')[-1] for x in train_df.iloc[test_index]['text']]\n",
    "        val_score = f1_score(train_df['label'].values[test_index].astype(str), val_pred, average='macro')\n",
    "        # print('Val length: ', len(val_pred))\n",
    "        print('Val score', val_score)\n",
    "        val_scores.append(val_score)\n",
    "\n",
    "    print('mean train score: ', np.mean(train_scores))\n",
    "    print('mean val score: ', np.mean(val_scores))\n",
    "    train_time = time.time()\n",
    "    print('Train time: {:.2f}s'.format(train_time - start_time))\n",
    "\n",
    "    return models\n",
    "\n",
    "def fasttext_kfold_predict(models, n_splits):\n",
    "\n",
    "    pred_list = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    # 预测并保存\n",
    "    test_df = pd.read_csv('data/test_a.csv')\n",
    "\n",
    "    # 消耗时间较长\n",
    "    for model in models:\n",
    "        test_pred = [model.predict(x)[0][0].split('__')[-1] for x in test_df['text']]\n",
    "        pred_list.append(test_pred)\n",
    "\n",
    "    test_pred_label = pd.DataFrame(pred_list).T.apply(lambda row: np.argmax(np.bincount([row[i] for i in range(n_splits)])), axis=1)\n",
    "    test_pred_label.columns='label'\n",
    "\n",
    "    test_pred_label.to_csv('data/test_fastText_ridgeclassifier.csv', index=False)\n",
    "    print('Test predict saved.')\n",
    "    end_time = time.time()\n",
    "    print('Predict time:{:.2f}s'.format(end_time - start_time))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  nrows = 200000\n",
    "  train_num = int(nrows * 0.7)\n",
    "  n_splits = 3\n",
    "  lr=0.1\n",
    "  wordNgrams=2\n",
    "  minCount=1\n",
    "  epoch=25\n",
    "  loss='hs'\n",
    "  dim=200\n",
    "  models = fasttext_kfold_model(nrows, train_num, n_splits, lr=lr, wordNgrams=wordNgrams, minCount=minCount, epoch=epoch, loss=loss, dim=dim)\n",
    "  fasttext_kfold_predict(models, n_splits=n_splits)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}